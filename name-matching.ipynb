{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "setup",
   "metadata": {
    "marimo": {
     "name": "setup"
    }
   },
   "outputs": [],
   "source": [
    "# Initialization code that runs before all other cells\n",
    "import marimo as mo\n",
    "import pandas as pd\n",
    "from metaphone import doublemetaphone\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Hbol",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "source": [
    "# Name-Matching Exercise\n",
    "Data analysis exercise designed to test the ability to match records across datasets based on name matching. In the exercise, we will work with congressional data to identify and link politicians across different datasets.\n",
    "\n",
    "___\n",
    "***My Attempt***:\n",
    "\n",
    "I used a common key method called **Double Metaphone**. The method is better than the original Soundex method, returning both a primary and secondary code for each name, allowing for greater ambiguity.\n",
    "\n",
    "In my attempt,\n",
    " - I first split the names into - first, middle, last and suffix - for all the names in the reference and election year dataset. The class ´Namesplitter´ defines the REGEX that is used to split the names.\n",
    " - Using the split names, I generate a metaphone for each of the invidual splits. These are termed as *meta_first*, *meta_middle*, *meta_last* and *meta_suffix*.\n",
    " - Later, there is a simple matching between the metaphones. All the metaphones that matches in the election dataset with each ref name, are then collected as a list.\n",
    " - Finally, for some of the names where there are more than 1 match, I refine this list by simply matching the first and last name.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "***Disclaimer***: I have used ChatGPT LLM model, for generation of code, specifically the REGEX. Also, there are some parts of the code that are refined (or added docstring) using the LLM model. However, the original idea as well as the implementation is all done my me. I take the full responsiblity of the code.\n",
    "\n",
    "\n",
    "**Reference:**\n",
    "\n",
    " * [Fuzzy name matching techniques](https://www.babelstreet.com/blog/fuzzy-name-matching-techniques)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vblA",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "source": [
    "---\n",
    "## STEP1: Loading CSV and Generating Metaphones"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bkHC",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "source": [
    "### Reference List\n",
    "I extract all the names from the `congress_members_with_parties.csv` to create a seperate dataframe called `ref_name`. This is the dataframe that contains all the names split into - first, middle, last and suffix. The `ref_name` also contains the doublemetaphone of each of the columns, which is the basis for matching."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "PKri",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are the names that did not split perfectly with the splitter.\n",
    "# Total are 46/2873.\n",
    "# idx = ref_name[ref_name[\"first\"].isna()].index\n",
    "# df.loc[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Xref",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "source": [
    "### Election Data\n",
    "This is the election data, where we will try to match the names from the `ref_name`. We combine all the election year data into single dataframe. This will help in name matching later from a single dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "BYtC",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "source": [
    "---\n",
    "## STEP2: Name Matching using Double Metaphone.\n",
    "Now we match the names in the `ref_name` with the names in the election list - `ele_name`. The matching is happening based on the metaphone for each \"first\", \"middle\", \"last\" and \"suffix\".\n",
    "\n",
    "In the dataframe, the following columns are:\n",
    " * `original`: names in the reference dataset.\n",
    " * `first`, `middle`, `last`, `suffix`: original name divided into 4 respective parts.\n",
    " * `metahone`: double metaphone that is combined together. For example, double metaphone for JOHNSON > [JNSN, ANSN]. We combine them as JNSNANSN.\n",
    " * `matches`: name that are matched from the `ele_name` dataframe.\n",
    " * `matched_metaphones`: metaphones of the matched names from the `ele_name` dataframe.\n",
    " * `match_count`: number of matches."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Kclp",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "source": [
    "### Further refinement of matched names\n",
    "As there are around 71 names that have more than 1 match, I am using refining the matches using one-to-one first and last name matching with the original name."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "iLit",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "source": [
    "---\n",
    "# Useful functions\n",
    " - Normalization of name\n",
    " - Namesplitter class\n",
    " - Generation of doublemetaphone\n",
    " - Matching algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ZHCJ",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     },
     "name": "*norm_meta"
    }
   },
   "outputs": [],
   "source": [
    "def norm_meta(val):\n",
    "    \"\"\"Normalize name strings: handle NaN, trim, and uppercase for consistency.\"\"\"\n",
    "    if pd.isna(val):\n",
    "        return \"\"\n",
    "    return str(val).strip().upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ROlb",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "outputs": [],
   "source": [
    "class NameSplitter:\n",
    "    \"\"\"\n",
    "    NameSplitter\n",
    "    ------------\n",
    "    Parses Western-style names into components (first, middle, last, suffix),\n",
    "    with support for:\n",
    "      • Formats: \"First [Middles] Last [Suffix]\" and \"Last[ Suffix], First [Middles] [Suffix]\"\n",
    "      • Pre- or post-comma suffixes in Mode A (e.g., \"Roth Jr., William V.\")\n",
    "      • Multiple middle names and initials (e.g., \"M. V.\")\n",
    "      • Honorifics (ignored): Mr., Dr., Justice, Sen., …\n",
    "      • Hyphens and apostrophes in names\n",
    "      • Optional comma before suffix in Mode B\n",
    "      • Single-token fallback (e.g., \"Neff\" → first=\"Neff\")\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    >>> ns = NameSplitter()\n",
    "    >>> ns.split(\"Atkinson, Eugene V.\")\n",
    "    {'first': 'Eugene', 'middle': 'V.', 'last': 'Atkinson', 'suffix': ''}\n",
    "\n",
    "    >>> ns.split(\"Froehlich, Harold V.\")\n",
    "    {'first': 'Harold', 'middle': 'V.', 'last': 'Froehlich', 'suffix': ''}\n",
    "\n",
    "    >>> ns.split(\"Roth Jr., William V.\")\n",
    "    {'first': 'William', 'middle': 'V.', 'last': 'Roth', 'suffix': 'Jr'}\n",
    "\n",
    "    >>> ns.split(\"Anthony Ravosa, Jr.\")\n",
    "    {'first': 'Anthony', 'middle': '', 'last': 'Ravosa', 'suffix': 'Jr'}\n",
    "\n",
    "    >>> ns.split(\"John McCain III\")\n",
    "    {'first': 'John', 'middle': '', 'last': 'McCain', 'suffix': 'III'}\n",
    "\n",
    "    >>> ns.split(\"Neff\")\n",
    "    {'first': 'Neff', 'middle': '', 'last': '', 'suffix': ''}\n",
    "    \"\"\"\n",
    "\n",
    "    # Recognized suffixes (dotted/undotted Jr/Sr, Roman numerals, common post-nominals)\n",
    "    SUFFIX_ATOM = (\n",
    "        r\"(?:Jr\\.?|Sr\\.?|II|III|IV|V|VI|VII|VIII|IX|X|\"\n",
    "        r\"Esq\\.?|Ph\\.?D\\.?|M\\.?D\\.?|J\\.?D\\.?|LL\\.?M\\.?|MBA|CFA|CPA|DDS)\"\n",
    "    )\n",
    "\n",
    "    # Middle token: allow dotted initials unconditionally, otherwise disallow suffix tokens\n",
    "    MIDDLE_TOKEN = rf\"(?:[A-Za-z]\\.|(?!{SUFFIX_ATOM}\\b)[\\w'.-]+)\"\n",
    "\n",
    "    NAME_REGEX = re.compile(\n",
    "        rf\"\"\"\n",
    "    ^\\s*\n",
    "    (?:\n",
    "      # ------------------------------------------------------------\n",
    "      # B) \"First [Middles] Last [Suffix]\"  (preferred branch)\n",
    "      # ------------------------------------------------------------\n",
    "      (?:(?P<prefix_b>(?:Mr|Mrs|Ms|Miss|Mx|Dr|Prof|Hon|Rev|Fr|Sir|Dame|Judge|Justice|Sen|Rep|Gov|President)\\.?)\\s+)?   # honorific\n",
    "      (?:(?P<lead_inits_b>(?:[A-Za-z]\\.)+(?:\\s+(?:[A-Za-z]\\.))*)\\s+)?                                                  # leading initials\n",
    "      (?P<first_b>[A-Za-z][\\w'.-]*)                                                                                    # first name\n",
    "      (?:\\s+(?P<middle_b>{MIDDLE_TOKEN}(?:\\s+{MIDDLE_TOKEN})*))?                                                       # middle(s)\n",
    "      \\s+\n",
    "      # last: multiple tokens allowed; do not consume suffix tokens\n",
    "      (?P<last_b>(?!{SUFFIX_ATOM}\\b)[\\w'.-]+(?:\\s+(?!{SUFFIX_ATOM}\\b)[\\w'.-]+)*)                                       # last\n",
    "      (?:\\s*,?\\s*(?P<suffix_b>{SUFFIX_ATOM}))?                                                                         # optional suffix (comma OK)\n",
    "\n",
    "    |\n",
    "      # ------------------------------------------------------------\n",
    "      # A) \"Last[ Suffix], First [Middles] [Suffix]\"\n",
    "      #     (allow pre-comma suffix immediately after last)\n",
    "      # ------------------------------------------------------------\n",
    "      (?P<last_a>[\\w'.-]+(?:\\s+[\\w'.-]+)*)                                                                             # last\n",
    "      (?:\\s+(?P<suffix_pre_a>{SUFFIX_ATOM}))?                                                                          # pre-comma suffix\n",
    "      \\s*,\\s*\n",
    "      (?:(?P<prefix_a>(?:Mr|Mrs|Ms|Miss|Mx|Dr|Prof|Hon|Rev|Fr|Sir|Dame|Judge|Justice|Sen|Rep|Gov|President)\\.?)\\s+)?    # honorific\n",
    "      (?:(?P<lead_inits_a>(?:[A-Za-z]\\.)+(?:\\s+(?:[A-Za-z]\\.))*)\\s+)?                                                  # leading initials\n",
    "      (?P<first_a>(?!{SUFFIX_ATOM}(?:\\s|$))[A-Za-z][\\w'.-]*)                                                            # first (not a suffix)\n",
    "      (?:\\s+(?P<middle_a>{MIDDLE_TOKEN}(?:\\s+{MIDDLE_TOKEN})*))?                                                        # middle(s)\n",
    "      (?:\\s*,?\\s*(?P<suffix_a>{SUFFIX_ATOM}))?                                                                          # post-comma suffix\n",
    "    )\n",
    "    \\s*$\n",
    "    \"\"\",\n",
    "        re.VERBOSE | re.IGNORECASE | re.UNICODE,\n",
    "    )\n",
    "\n",
    "    def split(self, full_name: str):\n",
    "        \"\"\"\n",
    "        Parse a full name into structured parts.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        full_name : str\n",
    "            Name in \"First Last [Suffix]\" or \"Last[, Suffix], First [Middles] [Suffix]\" form.\n",
    "            Single-token names are accepted via a fallback.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        dict or None\n",
    "            Keys: 'first', 'middle', 'last', 'suffix' (suffix normalized without trailing dot).\n",
    "            Returns None only if the string cannot be reasonably parsed.\n",
    "        \"\"\"\n",
    "        if not isinstance(full_name, str):\n",
    "            return None\n",
    "        s = full_name.strip()\n",
    "        if not s:\n",
    "            return None\n",
    "\n",
    "        m = self.NAME_REGEX.match(s)\n",
    "        if m:\n",
    "            if m.group(\"last_a\"):  # Mode A (comma present)\n",
    "                first = m.group(\"first_a\") or \"\"\n",
    "                lead = (m.group(\"lead_inits_a\") or \"\").strip()\n",
    "                middle = \" \".join(\n",
    "                    x for x in [lead, m.group(\"middle_a\") or \"\"] if x\n",
    "                )\n",
    "                last = m.group(\"last_a\") or \"\"\n",
    "                suffix = m.group(\"suffix_a\") or m.group(\"suffix_pre_a\") or \"\"\n",
    "            else:  # Mode B\n",
    "                first = m.group(\"first_b\") or \"\"\n",
    "                lead = (m.group(\"lead_inits_b\") or \"\").strip()\n",
    "                middle = \" \".join(\n",
    "                    x for x in [lead, m.group(\"middle_b\") or \"\"] if x\n",
    "                )\n",
    "                last = m.group(\"last_b\") or \"\"\n",
    "                suffix = m.group(\"suffix_b\") or \"\"\n",
    "\n",
    "            norm = lambda x: re.sub(r\"\\s+\", \" \", x or \"\").strip()\n",
    "            return {\n",
    "                \"first\": norm_meta(norm(first)),\n",
    "                \"middle\": norm_meta(norm(middle)),\n",
    "                \"last\": norm_meta(norm(last)),\n",
    "                \"suffix\": norm(suffix).rstrip(\".\"),\n",
    "            }\n",
    "\n",
    "        # --- Fallback: single-token names (e.g., \"Neff\") ---\n",
    "        token = re.sub(r\"\\s+\", \" \", s)\n",
    "        if \" \" not in token and not re.fullmatch(\n",
    "            self.SUFFIX_ATOM, token, flags=re.IGNORECASE\n",
    "        ):\n",
    "            return {\"first\": token, \"middle\": \"\", \"last\": \"\", \"suffix\": \"\"}\n",
    "\n",
    "        return None\n",
    "\n",
    "\n",
    "## Test\n",
    "# s = NameSplitter()\n",
    "# for n in [\n",
    "#    \"Ness\",\n",
    "#    \"Tuika Tuika\",\n",
    "#    \"Anthony Ravosa, Jr.\",\n",
    "#    \"Ravosa, Anthony, Jr.\",\n",
    "#    \"Pallone, Frank Jr.\",\n",
    "#    \"Frank Pallone, Jr.\",\n",
    "#    \"John McCain III\",\n",
    "#    \"Earl Hilliard, Sr.\",\n",
    "#    \"Justice Ralph Forbes\",\n",
    "#    \"Y. Tim Hutchinson\",\n",
    "#    \"Tautai Avaita Fano Fa'alevao\",\n",
    "#    \"Ballance, Frank W., Jr\",\n",
    "#    \"Barca, Peter\",\n",
    "#    \"Atkinson, Eugene V.\",\n",
    "#    \"Froehlich, Harold V.\",\n",
    "#    \"Roth Jr., William V.\",\n",
    "# ]:\n",
    "#    print(n, \"->\\t\", s.split(n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "MJUe",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "outputs": [],
   "source": [
    "# Name splitter --> Divide the name into first, middle, last and suffix\n",
    "splitter = NameSplitter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "qnkX",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "outputs": [],
   "source": [
    "def extract_metaphone(\n",
    "    df: pd.DataFrame, name_col: str, splitter: NameSplitter\n",
    ") -> (pd.DataFrame, int):\n",
    "    \"\"\"\n",
    "    Extract names and then split them.\n",
    "    We will also drop all the rows that have none value after the splitter.\n",
    "    Then from all the left dataframe, then names are converted to metaphone.\n",
    "    \"\"\"\n",
    "\n",
    "    # ----- Reference name list  -----#\n",
    "    # Extract the just the names from the main csv.\n",
    "    return_df = df[name_col].apply(splitter.split).apply(pd.Series)\n",
    "    return_df[\"original\"] = df[name_col]\n",
    "    # Drop all the empty. This is to remove all the float elements when converting to doublemetaphone.\n",
    "    return_df.dropna(inplace=True)\n",
    "    print(\n",
    "        f\"Dropped {len(df) - len(return_df)} number of rows with names, out of {len(df)} names due to splitting issues.\"\n",
    "    )\n",
    "\n",
    "    # ----- Double metaphone for names -----#\n",
    "    # I only use the first metaphone from the doublemetaphone.\n",
    "    def get_metaphone(name: str) -> str:\n",
    "        metaphones = doublemetaphone(name)\n",
    "        return \"\".join(metaphones)\n",
    "\n",
    "    # Adding metaphone for each of the parts of the name\n",
    "    metaphone_cols = [\"first\", \"middle\", \"last\", \"suffix\"]\n",
    "    for col in return_df[metaphone_cols]:\n",
    "        return_df[f\"meta_{col}\"] = return_df[col].apply(get_metaphone)\n",
    "\n",
    "    # Create metaphone column for reference later.\n",
    "    return_df[\"metaphone\"] = (\n",
    "        return_df[[\"meta_first\", \"meta_middle\", \"meta_last\", \"meta_suffix\"]]\n",
    "        .fillna(\"\")  # Replace NaN with empty string\n",
    "        .agg(\",\".join, axis=1)  # Join strings in each row\n",
    "        .str.strip()  # Remove any accidental spaces\n",
    "    )\n",
    "\n",
    "    return return_df, (len(df) - len(return_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lEQa",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "outputs": [],
   "source": [
    "# Load the primary dataset\n",
    "df = pd.read_csv(\"data/congress_members_with_parties.csv\")\n",
    "df.reset_index(inplace=True)\n",
    "\n",
    "# ----- Reference name list  -----#\n",
    "ref_name, n_dropped_ref_names = extract_metaphone(\n",
    "    df,\n",
    "    name_col=\"name\",\n",
    "    splitter=splitter,\n",
    ")\n",
    "ref_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "SFPL",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "outputs": [],
   "source": [
    "# Read all the election data for all the yeards from the each individual csv.\n",
    "all_years_ele = list()\n",
    "for y in range(1992, 2026, 1):\n",
    "    try:\n",
    "        t = pd.read_csv(f\"data/congressional_elections_{y}.csv\")\n",
    "        all_years_ele.append(t)\n",
    "    except pd.errors.EmptyDataError:\n",
    "        print(f\"CSV for year:{y} is empty!\")\n",
    "        pass\n",
    "# Concat the dataframes\n",
    "election = pd.concat(all_years_ele, ignore_index=True)\n",
    "\n",
    "# ----- Name list from year  -----#\n",
    "ele_name, n_dropped_names_ele = extract_metaphone(\n",
    "    election, name_col=\"name\", splitter=splitter\n",
    ")\n",
    "ele_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Hstk",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "TqIu",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     },
     "name": "*match_by_metaphone"
    }
   },
   "outputs": [],
   "source": [
    "def match_by_metaphone(\n",
    "    ref_df: pd.DataFrame,\n",
    "    ele_df: pd.DataFrame,\n",
    "    matching_cols=[\"meta_first\", \"meta_middle\", \"meta_last\", \"meta_suffix\"],\n",
    "    metaphone_col: str = \"metaphone\",\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    For each row in ref_df, find ele_df rows where all matching_cols match (after norm_meta).\n",
    "    Return both the matched 'original' names and the matched row-level 'metaphone' strings.\n",
    "\n",
    "    Output columns:\n",
    "      - original, first, middle, last, suffix, metaphone (from ref_df)\n",
    "      - matches: list[str] of matched ele_df['original']\n",
    "      - matched_metaphones: list[str] of matched ele_df[metaphone_col]\n",
    "      - match_count: int\n",
    "    \"\"\"\n",
    "    # Copies for safe mutation\n",
    "    ref = ref_df.copy()\n",
    "    ele = ele_df.copy()\n",
    "\n",
    "    # Normalize keys\n",
    "    for col in matching_cols:\n",
    "        ref[col] = ref[col].map(norm_meta)\n",
    "        ele[col] = ele[col].map(norm_meta)\n",
    "\n",
    "    # --- Build lookup: key -> {\"original\": [...], \"metaphone\": [...]}\n",
    "    # We aggregate both columns in one go, deduplicated & sorted for stability\n",
    "    agg = (\n",
    "        ele.groupby(matching_cols)[[\"original\", metaphone_col]]\n",
    "        .agg(\n",
    "            {\n",
    "                \"original\": lambda s: sorted(set(map(str.strip, map(str, s)))),\n",
    "                metaphone_col: lambda s: sorted(\n",
    "                    set(map(str.strip, map(str, s)))\n",
    "                ),\n",
    "            }\n",
    "        )\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    # Convert group result into a dictionary keyed by the tuple key\n",
    "    def _row_to_key(row):\n",
    "        return tuple(row[c] for c in matching_cols)\n",
    "\n",
    "    ele_lookup = {\n",
    "        _row_to_key(row): {\n",
    "            \"original\": row[\"original\"],\n",
    "            \"metaphone\": row[metaphone_col],\n",
    "        }\n",
    "        for _, row in agg.iterrows()\n",
    "    }\n",
    "\n",
    "    # --- For each ref row, collect matches\n",
    "    keys = list(zip(*[ref[col] for col in matching_cols]))\n",
    "    name_matches = []\n",
    "    meta_matches = []\n",
    "    for k in keys:\n",
    "        hit = ele_lookup.get(k)\n",
    "        if hit:\n",
    "            name_matches.append(hit[\"original\"])\n",
    "            meta_matches.append(hit[\"metaphone\"])\n",
    "        else:\n",
    "            name_matches.append([])\n",
    "            meta_matches.append([])\n",
    "\n",
    "    # --- Assemble output\n",
    "    out = ref.copy()\n",
    "    out[\"matches\"] = name_matches\n",
    "    out[\"matched_metaphones\"] = meta_matches\n",
    "    out[\"match_count\"] = out[\"matches\"].apply(len)\n",
    "\n",
    "    # Keep tidy columns if present\n",
    "    desired_cols = [\n",
    "        \"original\",\n",
    "        \"first\",\n",
    "        \"middle\",\n",
    "        \"last\",\n",
    "        \"suffix\",\n",
    "        metaphone_col,  # the ref row's metaphone\n",
    "        \"matches\",\n",
    "        \"matched_metaphones\",\n",
    "        \"match_count\",\n",
    "    ]\n",
    "    existing = [c for c in desired_cols if c in out.columns]\n",
    "    return out[existing].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "RGSE",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "outputs": [],
   "source": [
    "matched_df = match_by_metaphone(\n",
    "    ref_df=ref_name,\n",
    "    ele_df=ele_name,\n",
    ")\n",
    "matched_df.sort_values(by=\"match_count\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "emfo",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "outputs": [],
   "source": [
    "def refine_names_row(row: pd.Series, splitter):\n",
    "    matched_names = row[\"matches\"]\n",
    "    r_first = row.get(\"first\", \"\")\n",
    "    r_last = row.get(\"last\", \"\")\n",
    "\n",
    "    new_list = []\n",
    "    for name in matched_names:\n",
    "        try:\n",
    "            parts = splitter.split(\n",
    "                name\n",
    "            )  # expected to return dict-like with 'first' and 'last'\n",
    "            c_first = parts.get(\"first\", \"\") if isinstance(parts, dict) else \"\"\n",
    "            c_last = parts.get(\"last\", \"\") if isinstance(parts, dict) else \"\"\n",
    "            if (c_first == r_first) and (c_last == r_last):\n",
    "                new_list.append(name)\n",
    "        except Exception:\n",
    "            # If splitter fails for any candidate, just skip it\n",
    "            continue\n",
    "    return new_list\n",
    "\n",
    "\n",
    "# Copy of matched_df\n",
    "refined_matched_df = matched_df.copy()\n",
    "\n",
    "# Work only on rows that need refinement\n",
    "mask = refined_matched_df[\"match_count\"] > 1\n",
    "\n",
    "# Apply the row-wise refinement (same logic you used, just safer)\n",
    "refined_matched_df.loc[mask, \"matches\"] = refined_matched_df.loc[mask].apply(\n",
    "    lambda x: refine_names_row(x, splitter), axis=1\n",
    ")\n",
    "\n",
    "# Recompute match_count for just the affected rows\n",
    "refined_matched_df.loc[mask, \"match_count\"] = refined_matched_df.loc[\n",
    "    mask, \"matches\"\n",
    "].apply(len)\n",
    "refined_matched_df.sort_values(by=\"match_count\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nWHF",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "outputs": [],
   "source": [
    "mo.md(\n",
    "    f\"\"\"\n",
    "# Final Result\n",
    "Out of **{len(df)}** names in the original csv - \"congress_members_with_parties.csv\", the following are the resutls:\n",
    "\n",
    "\n",
    "- Number of names matched in original dataset with names in election year dataset \"congressional_elections_*year*.csv\":  **{sum(refined_matched_df[\"match_count\"] > 0)}**\n",
    "- Number of names with more than one match: **{sum(refined_matched_df[\"match_count\"] > 1)}**\n",
    "- Number of names dropped in original dataframe because of wrong splitting: **{n_dropped_ref_names}**\n",
    "- Number of names dropped in merged election dataframe because of wrong splitting: **{n_dropped_names_ele}**\n",
    "\"\"\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
